<!DOCTYPE html>
<html>
    <head>
    <meta charset="utf-8">  
    <link rel="stylesheet" href="https://nobuchiyo.github.io/sample/stylesheet.css" />
    <title>数学の犬</title>
    <link rel="shortcut icon" href="1766069200_1girl, solo, crossed legs, from above, purple hair, grey eyes, smile, overalls, slippers, lace trim, forest_0.png" type="image/vnd.microsoft.icon">
    </head>
            <header>
                <h1>プログラミング全般について</h1>
                <nav>
                    <ul>
                        <li><a href="index.html">HOME</a></li>
                        <li><a href="math.html">学習歴</a></li>
                        <li><a href="programming.html">プログラミング</a></li>
                        <li><a　href="">YouTube</a></li>
                        <li><a>お問い合わせ</a></li>
                    </ul>
                </nav>
            </header>

            <main>
              <h2>XAMPPとMAMP</h2>
              <p>XAMPPもMAMPもともにPHPを動かす環境を提供してくれるようですが、プログラミングの書籍に書いてあるままに両方インストールしてしまいました。自分はWindowsなのでXAMPPがいいようです。MacだとMAMPがよいらしい。</p>
                
                
                
                <h2>Django</h2>
                <p>Djangoの使い方の初歩をネットで学びました。まずはコマンドプロンプトを開き作成したenv1というフォルダにcdコマンドで移動します。cd desktop\python\env1といった要領でデスクトップに作成したフォルダへ移動して、env1へ行く。Script￥activateで仮想環境を有効にする。調べたサイトの記述をもとにhttp://http://127.0.0.1:8000/で開発環境を作ることができました。</p>
                
                
                <h2>arXivから論文の概要を取得するコード</h2>
                <p>chatGPTに教えてもらったコードです。queryの行ではAIに関する2023年の論文を取得するように指定しています。少しいじくれば条件を変えて取得することもできます。<br>
                import feedparser<br>
                import requests<br>

                # arXiv APIのURLと検索クエリを設定する<br>
                arxiv_url = "http://export.arxiv.org/api/query"<br>
                query = "search_query=cat:cs.AI&sortBy=submittedDate&sortOrder=descending&start=0&max_results=10&date-range=2023-01-01%3A2023-12-31"<br>

                # 論文を取得する<br>
                response = requests.get(arxiv_url, params=query)<br>

                # 取得した論文をパースして情報を抽出する<br>
                feed = feedparser.parse(response.text)<br>
                for entry in feed.entries:<br>
                # 論文情報を取得する<br>
                title = entry.title<br>
                authors = ", ".join(author.name for author in entry.authors)<br>
                abstract = entry.summary<br>
                published = entry.published<br>

                # 結果を出力する<br>
                print(f"Title: {title}")<br>
                print(f"Authors: {authors}")<br>
                print(f"Abstract: {abstract}")<br>
                print(f"Published: {published}")<br>
                print()<br>
                </p>
                
                
                
                
            </main>
      <footer>

      </footer>
        
</html>
